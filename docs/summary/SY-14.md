# SY-14 Summary: System Prompt (Phase 13)

**Ticket:** SY-14
**Branch:** `feature/sy-14-phase13`
**Status:** Released
**Date:** 2026-02-21

---

## What Was Done

Wired `config.system_prompt` through the `Agent` to all provider calls. The underlying
plumbing (`Role::System` enum variant, `Session.system_prompt` field, DB column
`system_prompt TEXT`) was already in place from earlier tickets. This ticket added the missing
glue connecting configuration to runtime behavior.

---

## Changes Made

### 1. `Config.system_prompt` field (`synapse-core/src/config.rs`)

Added `system_prompt: Option<String>` to the `Config` struct with `#[serde(default)]`:

```rust
#[serde(default)]
pub system_prompt: Option<String>,
```

Placed after `model` and before `session` in the struct definition. Added `system_prompt: None`
to `Config::default()`. The `#[serde(default)]` annotation ensures full backward compatibility:
existing config files without the field parse to `None` without error.

### 2. `Agent.system_prompt` and `with_system_prompt()` builder (`synapse-core/src/agent.rs`)

Added a private `system_prompt: Option<String>` field to `Agent`. `Agent::new()` signature is
unchanged — the field initializes to `None`. Added a public builder method:

```rust
pub fn with_system_prompt(mut self, prompt: impl Into<String>) -> Self {
    self.system_prompt = Some(prompt.into());
    self
}
```

Pattern consistent with `Session::with_system_prompt()` already in the codebase.

### 3. `build_messages()` private helper (`synapse-core/src/agent.rs`)

Implemented a private helper that constructs the final `Vec<Message>` for each provider call:

```rust
fn build_messages(&self, messages: &[Message]) -> Vec<Message> {
    match &self.system_prompt {
        Some(prompt) => {
            let mut result = Vec::with_capacity(messages.len() + 1);
            result.push(Message::new(Role::System, prompt.as_str()));
            result.extend_from_slice(messages);
            result
        }
        None => messages.to_vec(),
    }
}
```

Critical design point: `build_messages()` creates a new `Vec<Message>` every call. The
original `messages` parameter is never mutated with the system message. This ensures system
messages are never stored in the database — they exist only in the temporary vec passed to
the provider.

### 4. Integration into `complete()`, `stream()`, and `stream_owned()`

In `complete()`, `build_messages(messages)` is called at the top of every iteration of the
tool call loop. Tool results are appended to the original `messages` (not to
`provider_messages`). The system prompt is thus prepended fresh on every provider call.

In `stream()` and `stream_owned()` (no-tools path), `build_messages()` is called before
invoking the provider stream. When tools are active, these methods delegate to `complete()`,
which already calls `build_messages()` internally.

### 5. Wiring in CLI and Telegram

All three agent construction sites apply the same conditional builder pattern:

```rust
let agent = {
    let a = Agent::new(provider, mcp_client);
    match config.system_prompt {
        Some(ref prompt) => a.with_system_prompt(prompt),
        None => a,
    }
};
```

- `synapse-cli/src/main.rs` — one-shot mode
- `synapse-cli/src/repl.rs` — REPL mode
- `synapse-telegram/src/main.rs` — Telegram bot (before `Arc::new()`)

The `ref` borrow prevents moving out of `config`, which is still needed after agent
construction (e.g., for storage config or `Arc<Config>` wrapping).

### 6. `config.example.toml` update

Added a commented example after the `model` field and before the `[session]` section:

```toml
# System prompt prepended to every LLM conversation.
# This shapes the AI's personality and instructions across all interactions.
# Keep it concise to minimize token usage.
# system_prompt = "You are a helpful programming assistant."
```

---

## Key Design Decisions

### On-the-fly injection, never stored

The system prompt is injected by `build_messages()` at call time, not written to the database.
The DB schema has a `system_prompt TEXT` column on `sessions` (from earlier tickets), but this
ticket does not use it — the config-level prompt is the authoritative source, applied
dynamically on every provider call. This means:

- Resuming a session applies the *current* config's system prompt, not a historical one.
- No duplicate system messages accumulate in the message history across the tool call loop.

### Backward compatibility by construction

`Agent::new()` signature is unchanged. `with_system_prompt()` is an optional builder; omitting
it leaves `system_prompt: None` and produces behavior identical to pre-SY-14. Config files
without `system_prompt` parse cleanly due to `#[serde(default)]`.

### No provider changes needed

All three providers (Anthropic, DeepSeek, OpenAI) plus Mock already handled `Role::System`
correctly before this ticket:

- Anthropic: `extract_system()` lifts system messages into the top-level `system` API parameter.
- DeepSeek / OpenAI: map `Role::System` to `"system"` role in the messages array.
- Mock: ignores messages entirely.

---

## Testing

10 new unit tests (all passing):

**`synapse-core/src/config.rs` (3 tests):**
- `test_config_with_system_prompt` — TOML with field parses to `Some(...)`
- `test_config_without_system_prompt` — TOML without field parses to `None`
- `test_config_default_system_prompt` — `Config::default().system_prompt == None`

**`synapse-core/src/agent.rs` (7 tests):**
- `test_agent_default_system_prompt_none` — `Agent::new()` defaults to `None`
- `test_agent_with_system_prompt` — builder sets the field correctly
- `test_build_messages_with_system_prompt` — prepends `Role::System` message
- `test_build_messages_without_system_prompt` — returns messages unchanged
- `test_build_messages_preserves_original` — original slice not mutated
- `test_build_messages_with_history` — prepends before multi-message history
- `test_agent_complete_with_system_prompt` — `complete()` succeeds with system prompt set

**Regression:** 221 pre-existing tests, all passing.
**Quality gates:** `cargo fmt --check`, `cargo clippy -- -D warnings`, `cargo test` — all green.

---

## Files Changed

| File | Change |
|------|--------|
| `synapse-core/src/config.rs` | `system_prompt: Option<String>` field, `Default` update, 3 tests |
| `synapse-core/src/agent.rs` | `system_prompt` field, `with_system_prompt()`, `build_messages()`, integration, 7 tests |
| `synapse-cli/src/main.rs` | Conditional `with_system_prompt()` at agent construction |
| `synapse-cli/src/repl.rs` | Conditional `with_system_prompt()` at agent construction |
| `synapse-telegram/src/main.rs` | Conditional `with_system_prompt()` before `Arc::new()` |
| `config.example.toml` | Commented `system_prompt` example after `model` field |

## Files NOT Changed

All provider implementations (`anthropic.rs`, `deepseek.rs`, `openai.rs`, `mock.rs`),
`message.rs`, `session.rs`, `storage.rs`, `lib.rs`, and all DB migrations — unchanged.
No new core exports needed; `Config` and `Agent` were already re-exported.
