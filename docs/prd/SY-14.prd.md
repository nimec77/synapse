# SY-14: Phase 13 — System Prompt

Status: PRD_READY

## Context / Idea

**Arguments:** SY-14 "Phase 13: System Prompt" docs/phase/phase-13.md

**Goal:** Wire `config.system_prompt` through the Agent to all provider calls.

The plumbing already exists (`Role::System`, `Session.system_prompt`, DB column `system_prompt TEXT`) but nothing injects a system prompt today. The goal is to wire `config.system_prompt` through the `Agent` so it prepends a `Role::System` message before every provider call without mutating the stored session history.

### Description File (phase-13.md) — Verbatim Specifications

**Tasks:**
- 13.1 Add `system_prompt: Option<String>` to `Config` struct
- 13.2 Add `system_prompt` field and `with_system_prompt()` builder to `Agent`
- 13.3 Implement `build_messages()` helper to prepend `Role::System` on-the-fly
- 13.4 Wire system prompt from config/session into Agent in CLI and Telegram
- 13.5 Update `config.example.toml` with `system_prompt` example

**Acceptance Criteria:**
Setting `system_prompt` in config causes a `Role::System` message to be prepended to every provider call.

**Key design points:**
- `build_messages()` constructs the final `Vec<Message>` slice passed to the provider — it prepends the system message on-the-fly so the DB never stores duplicate system messages.
- `with_system_prompt()` is a builder method on `Agent` for ergonomic construction.
- Both `synapse-cli` and `synapse-telegram` should read `config.system_prompt` and pass it to the agent at startup.

### Current State Analysis

| Component | Existing State | Gap |
|-----------|---------------|-----|
| `Role::System` | Exists in `message.rs` | None — ready to use |
| `Session.system_prompt` | Field exists, builder `with_system_prompt()` exists, DB column exists | Not wired to Agent |
| `Config` struct | No `system_prompt` field | Must add `system_prompt: Option<String>` |
| `Agent` struct | Has `provider` and `mcp_client` fields only | Must add `system_prompt` field and builder |
| `Agent::complete()` / `Agent::stream()` | Passes `messages` directly to provider | Must prepend system message via `build_messages()` |
| CLI (`synapse-cli/src/main.rs`) | Constructs `Agent::new(provider, mcp_client)` | Must pass `config.system_prompt` |
| Telegram (`synapse-telegram/src/main.rs`) | Constructs `Agent::new(provider, mcp_client)` | Must pass `config.system_prompt` |
| REPL (`synapse-cli/src/repl.rs`) | Constructs `Agent::new(provider, mcp_client)` | Must pass `config.system_prompt` |
| `config.example.toml` | No system prompt entry | Must add commented example |

## Goals

1. **Enable system prompt configuration:** Users can set a global `system_prompt` in `config.toml` that shapes all LLM interactions.
2. **Transparent injection:** The system prompt is prepended to every provider call on-the-fly, without being persisted as a duplicate in the session message history.
3. **Ergonomic API:** The `Agent` supports a `with_system_prompt()` builder pattern consistent with existing Rust conventions in the codebase.
4. **Uniform behavior:** Both CLI (one-shot, REPL) and Telegram interfaces respect the configured system prompt identically.
5. **Zero breaking changes:** Existing `Agent::new()` callers continue to work without modification (system prompt defaults to `None`).

## User Stories

1. **As a user**, I want to set a `system_prompt` in my `config.toml` so that every conversation starts with my preferred personality/instructions without me typing them each time.
2. **As a CLI user** using one-shot mode (`synapse "question"`), I want the system prompt to be included in the request to the LLM so that the response reflects my configured persona.
3. **As a CLI user** in REPL mode, I want the system prompt to be prepended to every provider call throughout the session so that multi-turn conversations consistently respect my instructions.
4. **As a Telegram user**, I want the bot to use the configured system prompt in every response so that it behaves the same as the CLI.
5. **As a developer**, I want the `Agent` to expose a `with_system_prompt()` builder so that I can programmatically set or override the system prompt when constructing an agent.
6. **As a user resuming a session**, I want the system prompt from config to still be prepended to provider calls without being stored as a duplicate message in the database.

## Main Scenarios

### Scenario 1: Config with system_prompt set

1. User adds `system_prompt = "You are a helpful Rust tutor."` to `config.toml`.
2. User runs `synapse "Explain lifetimes"`.
3. CLI loads config, reads `system_prompt`.
4. CLI constructs `Agent::new(provider, mcp_client).with_system_prompt("You are a helpful Rust tutor.")`.
5. Agent's `build_messages()` prepends `Message::new(Role::System, "You are a helpful Rust tutor.")` before the user message.
6. Provider receives `[System, User]` messages.
7. LLM responds with a Rust-tutor-flavored explanation.
8. Only the user message and assistant response are stored in the DB — no system message stored.

### Scenario 2: Config without system_prompt

1. User has no `system_prompt` in config (field is absent or `None`).
2. User runs `synapse "Hello"`.
3. Agent's `system_prompt` is `None`.
4. `build_messages()` returns the original messages unchanged (no system message prepended).
5. Behavior is identical to the current implementation.

### Scenario 3: REPL multi-turn with system prompt

1. User sets `system_prompt = "Respond only in haiku."` in config.
2. User enters REPL mode: `synapse --repl`.
3. For every turn (user message -> provider call), `build_messages()` prepends the system message.
4. The system message is never stored in the session; it exists only in the `Agent` struct and is injected on each call.
5. The user can send multiple messages, and every response reflects the haiku instruction.

### Scenario 4: Telegram with system prompt

1. Admin sets `system_prompt` in the server's `config.toml`.
2. Telegram bot starts, reads config, creates Agent with system prompt.
3. User sends a message via Telegram.
4. Handler loads session history, calls `agent.complete()`.
5. `build_messages()` prepends the system message before the conversation history.
6. Response is sent back to Telegram user, reflecting the system prompt's instructions.

### Scenario 5: Session resume with system prompt

1. User has `system_prompt` configured and resumes a session (`synapse -s <id> "follow up"`).
2. History is loaded from DB (no system messages in DB).
3. `build_messages()` prepends the current config's system prompt before the full history.
4. Provider sees `[System, ...history, User]`.
5. The system prompt is always the *current* config value, not a historical one.

## Success / Metrics

| Metric | Target |
|--------|--------|
| `Config` parses `system_prompt` field from TOML | Verified by unit test |
| `Agent` stores and exposes system prompt | Verified by unit test |
| `build_messages()` prepends `Role::System` when prompt is `Some` | Verified by unit test |
| `build_messages()` returns messages unchanged when prompt is `None` | Verified by unit test |
| System message is NOT stored in the database | Verified by examining DB after a conversation |
| CLI one-shot mode passes system prompt to Agent | Verified by code review and integration test |
| CLI REPL mode passes system prompt to Agent | Verified by code review and integration test |
| Telegram passes system prompt to Agent | Verified by code review |
| `config.example.toml` documents the field | Verified by file inspection |
| All existing tests pass (no regressions) | `cargo test` green |
| `cargo clippy -- -D warnings` passes | CI gate |
| `cargo fmt --check` passes | CI gate |

## Constraints and Assumptions

### Constraints

1. **`synapse-core` never imports from interface crates.** The `Agent` must provide the mechanism; CLI and Telegram wire the config value in.
2. **No `unwrap()`/`expect()` in `synapse-core`.** All error paths propagated with `?`.
3. **No `mod.rs` files.** New module system (Rust 2018+).
4. **DB schema unchanged.** The `system_prompt` column already exists on `sessions`. This ticket does not add migrations.
5. **Line limit:** 100 characters.
6. **`thiserror` in core, `anyhow` in CLI/Telegram.**

### Assumptions

1. The system prompt from `config.system_prompt` is the authoritative source for all new agent calls. Session-level `system_prompt` (already in the `Session` struct) is not used in this ticket's scope — the config-level one takes precedence.
2. The system prompt is a plain string with no variable interpolation or templating.
3. The system prompt is optional. Omitting it from config is the default and produces no behavioral change.
4. `build_messages()` is a private helper on `Agent`, not a public API. It constructs a temporary `Vec<Message>` for each provider call.

## Risks

| Risk | Likelihood | Impact | Mitigation |
|------|-----------|--------|------------|
| System prompt duplicated in DB if not handled carefully | Low | Medium | `build_messages()` constructs a new vec on-the-fly; the original `messages` slice is never mutated with the system message. Unit test verifies DB-stored messages do not contain system messages. |
| Breaking change to `Agent::new()` signature | Low | High | Keep `Agent::new(provider, mcp_client)` unchanged. Add `with_system_prompt()` as an optional builder method. All existing call sites work without modification. |
| System prompt conflicts with provider-specific system message handling (e.g., Anthropic uses a separate `system` parameter) | Medium | Low | Current Anthropic/DeepSeek providers already handle `Role::System` messages in the `messages` array. No special treatment needed at the provider level. |
| Long system prompts increase token usage and cost | Low | Low | Documentation in `config.example.toml` advises keeping system prompts concise. This is a user responsibility. |

## Open Questions

None — the requirements are well-defined, the existing plumbing (`Role::System`, `Session.system_prompt`, DB column) is in place, and the design points in the phase description are clear and actionable. All five tasks have concrete scope.
