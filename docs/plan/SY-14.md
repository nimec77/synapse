# SY-14 Plan: System Prompt (Phase 13)

Status: PLAN_APPROVED

## Overview

Wire `config.system_prompt` through the `Agent` to all provider calls. The plumbing already exists (`Role::System` enum variant, `Session.system_prompt` field, DB column `system_prompt TEXT`) but nothing injects a system prompt today. This ticket adds a `system_prompt` field to `Config`, adds `system_prompt` and a `with_system_prompt()` builder to `Agent`, implements a private `build_messages()` helper that prepends a `Role::System` message on-the-fly before every provider call, wires the config value into both CLI and Telegram agent construction, and documents the field in `config.example.toml`.

## Components

### 1. Config.system_prompt (`synapse-core/src/config.rs`)

Add `system_prompt: Option<String>` to the `Config` struct with `#[serde(default)]` so it defaults to `None` when absent from TOML.

#### 1.1 Config Struct Change

```rust
/// Application configuration loaded from TOML file.
#[derive(Debug, Clone, PartialEq, Deserialize)]
pub struct Config {
    // ... existing fields ...

    /// System prompt prepended to every LLM conversation.
    /// Shapes the AI's personality and instructions across all interactions.
    #[serde(default)]
    pub system_prompt: Option<String>,
}
```

The field is placed after `model` and before `session` in the struct definition, matching the logical ordering in `config.example.toml`.

**Requirement source:** Phase-13 task 13.1, PRD Goal 1.

#### 1.2 Config::default() Update

Add `system_prompt: None` to the `Default` implementation for `Config` (line 196).

#### 1.3 Tests

- `test_config_with_system_prompt` -- Parse TOML with `system_prompt = "You are helpful."`, verify `config.system_prompt == Some("You are helpful.".to_string())`.
- `test_config_without_system_prompt` -- Parse TOML without the field, verify `config.system_prompt == None`.
- `test_config_default_system_prompt` -- Verify `Config::default().system_prompt == None`.

**Pattern followed:** Same as `api_key: Option<String>` with `#[serde(default)]`.

### 2. Agent.system_prompt and with_system_prompt() Builder (`synapse-core/src/agent.rs`)

Add a `system_prompt: Option<String>` field to `Agent` and a builder method for ergonomic construction.

#### 2.1 Agent Struct Change

```rust
pub struct Agent {
    /// The LLM provider for generating responses.
    provider: Box<dyn LlmProvider>,
    /// Optional MCP client for tool execution.
    mcp_client: Option<McpClient>,
    /// Optional system prompt prepended to every provider call.
    system_prompt: Option<String>,
}
```

#### 2.2 Agent::new() Update

Initialize `system_prompt` to `None` in `Agent::new()`, preserving backward compatibility. All existing call sites (`Agent::new(provider, mcp_client)`) continue to work unchanged.

```rust
pub fn new(provider: Box<dyn LlmProvider>, mcp_client: Option<McpClient>) -> Self {
    Self {
        provider,
        mcp_client,
        system_prompt: None,
    }
}
```

#### 2.3 with_system_prompt() Builder

```rust
/// Set the system prompt prepended to every provider call.
///
/// The system prompt is injected on-the-fly via `build_messages()` and
/// is never stored in the session database.
pub fn with_system_prompt(mut self, prompt: impl Into<String>) -> Self {
    self.system_prompt = Some(prompt.into());
    self
}
```

**Pattern followed:** Identical to `Session::with_system_prompt()` at `session.rs` line 57.

**Requirement source:** Phase-13 task 13.2, PRD Goal 3, PRD Goal 5.

#### 2.4 Update Doc Comment Example

Update the `Agent` struct doc example to show `with_system_prompt` usage:

```rust
/// let agent = Agent::new(provider, None)
///     .with_system_prompt("You are a helpful assistant.");
```

#### 2.5 Tests

- `test_agent_default_system_prompt_none` -- Create agent with `Agent::new()`, verify system prompt defaults to `None`.
- `test_agent_with_system_prompt` -- Create agent with `.with_system_prompt("test")`, verify field is set.

### 3. build_messages() Helper (`synapse-core/src/agent.rs`)

Implement a private helper that constructs the final `Vec<Message>` passed to the provider, prepending a `Role::System` message when `self.system_prompt` is `Some`.

#### 3.1 Method Signature

```rust
/// Build the message slice for a provider call, prepending the
/// system prompt when configured.
///
/// Creates a new `Vec<Message>` each time. The caller's original
/// messages are never mutated with the system message.
fn build_messages(&self, messages: &[Message]) -> Vec<Message> {
    match &self.system_prompt {
        Some(prompt) => {
            let mut result = Vec::with_capacity(messages.len() + 1);
            result.push(Message::new(Role::System, prompt.as_str()));
            result.extend_from_slice(messages);
            result
        }
        None => messages.to_vec(),
    }
}
```

**Critical design point:** `build_messages()` returns a new `Vec<Message>`. The original `messages` parameter (which is `&mut Vec<Message>` in `complete()`) is never mutated with the system message. The system message exists only in the temporary vec passed to the provider. This ensures system messages are never stored in the DB.

**Requirement source:** Phase-13 task 13.3, PRD Goal 2, PRD Constraint 4.

#### 3.2 Integration into complete()

The `complete()` method (line 88) currently passes `messages` directly to the provider. The change:

```rust
pub async fn complete(&self, messages: &mut Vec<Message>) -> Result<Message, AgentError> {
    let tools = self.get_tool_definitions();

    for _ in 0..MAX_ITERATIONS {
        let provider_messages = self.build_messages(messages);
        let response = if tools.is_empty() {
            self.provider.complete(&provider_messages).await?
        } else {
            self.provider
                .complete_with_tools(&provider_messages, &tools)
                .await?
        };

        // ... tool call handling appends to `messages` (not provider_messages)
        // ... rest unchanged
    }
    // ...
}
```

On each iteration of the tool call loop:
1. `build_messages(messages)` creates a temporary vec with the system prompt prepended.
2. The provider receives the temporary vec (with system prompt).
3. Tool call results are appended to the original `messages` (without system prompt).
4. Next iteration, `build_messages()` prepends the system prompt again.

This ensures the system prompt is present on every provider call, but never accumulates in the original messages or the database.

#### 3.3 Integration into stream()

The `stream()` method (line 138) currently calls `self.provider.stream(messages)` directly. The change:

```rust
// No tools: direct streaming, no loop needed
return Box::pin(async_stream::stream! {
    let provider_messages = self.build_messages(messages);
    let mut stream = self.provider.stream(&provider_messages);
    // ... rest unchanged
});
```

When tools are available, `stream()` delegates to `self.complete(messages)`, which already calls `build_messages()` internally. No additional change needed for that path.

#### 3.4 Integration into stream_owned()

The `stream_owned()` method (line 176) follows the same pattern:

```rust
// No tools: direct streaming, no loop needed
return Box::pin(async_stream::stream! {
    let provider_messages = self.build_messages(&messages);
    let mut stream = self.provider.stream(&provider_messages);
    // ... rest unchanged
});
```

When tools are available, `stream_owned()` calls `self.complete(&mut messages)`, which already calls `build_messages()` internally. No additional change needed for that path.

#### 3.5 Tests

- `test_build_messages_with_system_prompt` -- Create agent with system prompt "You are helpful." and messages `[User("Hi")]`. Verify returned vec is `[System("You are helpful."), User("Hi")]`.
- `test_build_messages_without_system_prompt` -- Create agent without system prompt. Verify returned vec equals the input messages unchanged.
- `test_build_messages_preserves_original` -- Create agent with system prompt. Call `build_messages()` on a messages slice. Verify the original slice is unchanged (no system message added to it).
- `test_build_messages_with_history` -- Create agent with system prompt. Pass multi-message history `[User("Q1"), Assistant("A1"), User("Q2")]`. Verify returned vec is `[System("..."), User("Q1"), Assistant("A1"), User("Q2")]`.
- `test_agent_complete_with_system_prompt` -- Use `MockProvider` to verify that `complete()` works with a system prompt set. The mock ignores messages but the test verifies no errors occur and the agent completes successfully.

### 4. Wire System Prompt in CLI and Telegram

Pass `config.system_prompt` to the Agent via `with_system_prompt()` at each construction site.

#### 4.1 CLI One-Shot Mode (`synapse-cli/src/main.rs`)

Line 184 currently reads:
```rust
let agent = Agent::new(provider, mcp_client);
```

Change to:
```rust
let agent = {
    let a = Agent::new(provider, mcp_client);
    match config.system_prompt {
        Some(ref prompt) => a.with_system_prompt(prompt),
        None => a,
    }
};
```

`config` is a `Config` (not yet consumed), so `config.system_prompt` is accessible. The `ref` borrow prevents moving out of `config` which is still needed later for the `agent.shutdown()` scope.

**Requirement source:** Phase-13 task 13.4, PRD Scenario 1, PRD User Story 2.

#### 4.2 CLI REPL Mode (`synapse-cli/src/repl.rs`)

Line 498 currently reads:
```rust
let agent = Agent::new(provider, mcp_client);
```

Change to:
```rust
let agent = {
    let a = Agent::new(provider, mcp_client);
    match config.system_prompt {
        Some(ref prompt) => a.with_system_prompt(prompt),
        None => a,
    }
};
```

The `run_repl()` function signature already receives `config: &Config`, so `config.system_prompt` is accessible without any signature change.

**Requirement source:** Phase-13 task 13.4, PRD Scenario 3, PRD User Story 3.

#### 4.3 Telegram Bot (`synapse-telegram/src/main.rs`)

Line 83 currently reads:
```rust
let agent = Arc::new(Agent::new(provider, mcp_client));
```

Change to:
```rust
let agent = {
    let a = Agent::new(provider, mcp_client);
    match config.system_prompt {
        Some(ref prompt) => a.with_system_prompt(prompt),
        None => a,
    }
};
let agent = Arc::new(agent);
```

At this point `config` is still a plain `Config` (it gets wrapped in `Arc` at line 94), so `config.system_prompt` is accessible.

**Requirement source:** Phase-13 task 13.4, PRD Scenario 4, PRD User Story 4.

### 5. config.example.toml Update

Add a commented `system_prompt` example after the `model` field (line 21) and before the `[session]` section (line 23):

```toml
# System prompt prepended to every LLM conversation.
# This shapes the AI's personality and instructions across all interactions.
# Keep it concise to minimize token usage.
# system_prompt = "You are a helpful programming assistant."
```

**Requirement source:** Phase-13 task 13.5, PRD Success Metric ("config.example.toml documents the field").

## API Contract

### Internal: Agent API

The only public API change is the addition of `with_system_prompt()`:

```rust
impl Agent {
    // Existing (unchanged):
    pub fn new(provider: Box<dyn LlmProvider>, mcp_client: Option<McpClient>) -> Self;
    pub async fn complete(&self, messages: &mut Vec<Message>) -> Result<Message, AgentError>;
    pub fn stream<'a>(&'a self, messages: &'a mut Vec<Message>) -> Pin<Box<dyn Stream<...>>>;
    pub fn stream_owned(&self, messages: Vec<Message>) -> Pin<Box<dyn Stream<...>>>;
    pub async fn shutdown(self);

    // New:
    pub fn with_system_prompt(mut self, prompt: impl Into<String>) -> Self;
}
```

No new traits, errors, or module-level exports are needed. `Agent` is already re-exported from `synapse-core/src/lib.rs`.

### Internal: Config TOML

```toml
# New optional field at top level:
system_prompt = "You are a helpful programming assistant."
```

## Data Flows

### Flow 1: One-Shot CLI with System Prompt

```
1. User sets `system_prompt = "You are a Rust tutor."` in config.toml
2. User runs: synapse "Explain lifetimes"
3. CLI loads config, reads system_prompt = Some("You are a Rust tutor.")
4. CLI creates Agent::new(provider, mcp_client).with_system_prompt("You are a Rust tutor.")
5. CLI creates messages = [User("Explain lifetimes")]
6. CLI calls agent.stream(&mut messages)
7. Agent::stream() calls build_messages(messages)
8. build_messages() returns [System("You are a Rust tutor."), User("Explain lifetimes")]
9. Provider receives [System, User] -- provider handles system role correctly
10. Provider streams response tokens
11. CLI stores User and Assistant messages in DB -- no System message stored
12. System prompt exists only in Agent.system_prompt field, never in DB
```

### Flow 2: REPL Multi-Turn with System Prompt

```
1. User sets `system_prompt = "Respond only in haiku."` in config.toml
2. User enters REPL: synapse --repl
3. Agent created with system_prompt = Some("Respond only in haiku.")
4. Turn 1: User types "Hello"
   a. messages = [User("Hello")]
   b. build_messages() -> [System("...haiku..."), User("Hello")]
   c. Provider receives [System, User], returns Assistant response
   d. DB stores: User("Hello"), Assistant("...haiku...")
5. Turn 2: User types "What is Rust?"
   a. messages = [User("Hello"), Assistant("..."), User("What is Rust?")]
   b. build_messages() -> [System("...haiku..."), User("Hello"), Assistant("..."), User("What is Rust?")]
   c. Provider receives [System, User, Assistant, User], returns response
   d. DB stores: User("What is Rust?"), Assistant("...haiku...")
6. System prompt is prepended fresh on every provider call
7. System prompt is NEVER stored in DB
```

### Flow 3: Session Resume with System Prompt

```
1. User resumes session: synapse -s <uuid> "Follow up"
2. History loaded from DB: [User("Q1"), Assistant("A1")]
3. New user message appended: messages = [User("Q1"), Assistant("A1"), User("Follow up")]
4. build_messages() -> [System("..."), User("Q1"), Assistant("A1"), User("Follow up")]
5. Provider sees System + full history + new question
6. System prompt is the CURRENT config value, not a historical one
7. DB stores only User and Assistant messages
```

### Flow 4: No System Prompt Configured

```
1. Config has no system_prompt field (or system_prompt absent)
2. Agent.system_prompt = None
3. build_messages(messages) returns messages.to_vec() -- unchanged
4. Behavior identical to current implementation -- zero regression
```

### Flow 5: Telegram with System Prompt

```
1. Admin sets system_prompt in server config.toml
2. Bot starts, creates Agent with system_prompt
3. User sends message via Telegram
4. Handler loads session history, calls agent.complete(&mut messages)
5. build_messages() prepends system prompt before conversation history
6. Provider sees [System, ...history, User]
7. Response sent to Telegram, reflecting system prompt instructions
8. System prompt never stored in session DB
```

## Non-Functional Requirements

1. **Zero breaking changes:** `Agent::new()` signature is unchanged. `with_system_prompt()` is an optional builder. All existing call sites compile and work without modification. Config files without `system_prompt` produce `None` (default behavior).

2. **No DB schema changes:** The `system_prompt TEXT` column already exists on `sessions`. This ticket does not add migrations. The system prompt from config is injected at runtime, not persisted per-call.

3. **No core trait changes:** `LlmProvider`, `SessionStore`, and all other core traits are untouched. The system prompt is handled entirely within the `Agent` layer.

4. **No provider changes:** All three providers (Anthropic, DeepSeek, OpenAI) plus Mock already handle `Role::System` correctly:
   - **Anthropic:** `extract_system()` extracts system messages and passes them as the top-level `system` API parameter. `build_api_messages()` filters them out of the messages array. A single prepended system message is handled correctly.
   - **DeepSeek/OpenAI:** Map `Role::System` to `"system"` role inline in the messages array (standard OpenAI-compatible behavior).
   - **Mock:** Ignores messages entirely, returns configured responses.

5. **System prompt isolation:** `build_messages()` creates a new `Vec<Message>` each time. The original `messages` parameter is never mutated with the system message. This prevents system messages from leaking into DB storage.

6. **100 character line limit:** All new code respects the project's line limit.

7. **No `unwrap()`/`expect()` in `synapse-core`:** All new code in core uses `Option` matching and builder patterns. No error-prone unwrapping.

## Risks and Mitigations

| Risk | Likelihood | Impact | Mitigation |
|------|-----------|--------|------------|
| System prompt duplicated in DB if `build_messages()` mutates original messages | Low | Medium | `build_messages()` creates a new vec; original `messages` is never mutated. Unit test `test_build_messages_preserves_original` verifies this explicitly. |
| Breaking change to `Agent::new()` signature | None | High | `Agent::new()` signature is unchanged. `system_prompt` defaults to `None`. `with_system_prompt()` is an optional builder method. |
| Anthropic double system prompt (user-provided + config-injected) | Low | Low | Current implementation prepends one system message. Anthropic provider's `extract_system()` joins all system messages with `"\n\n"`. If a user also passes system messages in their conversation history, they will be concatenated -- this is correct behavior. |
| Long system prompts increasing token usage | Low | Low | Documentation in `config.example.toml` advises keeping prompts concise. User responsibility. |
| `build_messages()` cloning messages on every call adds overhead | Low | Low | Messages are cloned once per provider call. For typical conversation lengths (< 100 messages), this is negligible compared to network latency of the LLM API call. |

## Deviations to Fix

**None.** The research document confirms zero deviations between the existing codebase and the requirements:
- `Role::System` exists and works.
- `Session.system_prompt` exists with builder.
- DB column exists.
- All providers handle `Role::System` correctly.
- `Agent::new()` will remain backward-compatible with the builder pattern addition.
- No schema changes needed.

## Testing Strategy

### Unit Tests: synapse-core/src/config.rs (3 tests)

| Test | Purpose |
|------|---------|
| `test_config_with_system_prompt` | TOML with `system_prompt` parses to `Some(...)` |
| `test_config_without_system_prompt` | TOML without field parses to `None` |
| `test_config_default_system_prompt` | `Config::default().system_prompt == None` |

### Unit Tests: synapse-core/src/agent.rs (7 tests)

| Test | Purpose |
|------|---------|
| `test_agent_default_system_prompt_none` | `Agent::new()` has `system_prompt: None` |
| `test_agent_with_system_prompt` | Builder sets the field correctly |
| `test_build_messages_with_system_prompt` | Prepends `Role::System` message |
| `test_build_messages_without_system_prompt` | Returns messages unchanged |
| `test_build_messages_preserves_original` | Original slice not mutated |
| `test_build_messages_with_history` | Prepends before multi-message history |
| `test_agent_complete_with_system_prompt` | `complete()` succeeds with system prompt set |

**Note on MockProvider limitation:** The current `MockProvider` ignores the `messages` parameter. To verify `build_messages()` prepends correctly, we test the private `build_messages()` method directly within the `#[cfg(test)]` module. This is appropriate since `build_messages()` is a private helper per the PRD.

### Regression

All existing `cargo test` must pass. The changes are additive:
- New optional field on `Config` (serde-defaulted)
- New optional field on `Agent` (defaults to `None`)
- New builder method on `Agent`
- `build_messages()` integration uses existing provider API unchanged

### Pre-commit Gate

```bash
cargo fmt --check && cargo clippy -- -D warnings && cargo test
```

**Total: 10 new unit tests (3 config + 7 agent).**

## File Changes Summary

| File | Change Type | Description |
|------|-------------|-------------|
| `synapse-core/src/config.rs` | Modify | Add `system_prompt: Option<String>` to `Config`, update `Default`, add 3 tests |
| `synapse-core/src/agent.rs` | Modify | Add `system_prompt` field, `with_system_prompt()` builder, `build_messages()` helper, integrate into `complete()`/`stream()`/`stream_owned()`, add 7 tests |
| `synapse-cli/src/main.rs` | Modify | Wire `config.system_prompt` to Agent construction (line 184) |
| `synapse-cli/src/repl.rs` | Modify | Wire `config.system_prompt` to Agent construction (line 498) |
| `synapse-telegram/src/main.rs` | Modify | Wire `config.system_prompt` to Agent construction (line 83) |
| `config.example.toml` | Modify | Add commented `system_prompt` example after `model` field |

### Files NOT Modified

- `synapse-core/src/lib.rs` -- No new exports needed; `Config` and `Agent` already exported.
- `synapse-core/src/message.rs` -- `Role::System` and `Message::new()` already exist.
- `synapse-core/src/session.rs` -- `Session.system_prompt` already exists, not used in this ticket's scope.
- `synapse-core/src/provider.rs` -- All providers already handle `Role::System` correctly.
- `synapse-core/src/storage.rs` -- No schema or trait changes.
- `synapse-core/migrations/` -- DB column already exists.

## Implementation Order

1. **Task 13.1** -- `Config.system_prompt` field + `Default` update + 3 tests (no dependencies)
2. **Task 13.2** -- `Agent.system_prompt` field + `with_system_prompt()` builder + 2 tests (no external dependencies)
3. **Task 13.3** -- `build_messages()` helper + integration into `complete()`/`stream()`/`stream_owned()` + 5 tests (depends on 13.2)
4. **Task 13.4** -- Wire in CLI main (line 184), REPL (line 498), and Telegram (line 83) (depends on 13.1 + 13.3)
5. **Task 13.5** -- Update `config.example.toml` (independent, can be done anytime)

Tasks 13.1 and 13.2 can be executed in parallel. Task 13.3 depends on 13.2. Task 13.4 depends on both 13.1 and 13.3. Task 13.5 has no dependencies.

## Open Questions

None. The requirements are well-defined, the existing plumbing is in place, and the research document confirmed zero deviations. All five tasks have concrete scope with clear file locations and line numbers.
