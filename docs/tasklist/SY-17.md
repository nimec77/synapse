# SY-17 Tasklist: Configurable max_tokens

**Ticket:** SY-17
**Status:** IMPLEMENT_STEP_OK
**Date:** 2026-02-24

## Context

All three LLM providers (`AnthropicProvider`, `DeepSeekProvider`, `OpenAiProvider`) hardcode `DEFAULT_MAX_TOKENS = 1024` in their API requests. The `Config` struct has no `max_tokens` field, and `create_provider()` does not pass any token limit to providers. This ticket adds a configurable `max_tokens: u32` field to `Config` (default `4096`), propagates it through the provider factory into all three provider structs, replaces every hardcoded `DEFAULT_MAX_TOKENS` reference, updates `config.example.toml`, and adds the required unit test.

---

## Tasks

- [x] **Task 1: Add `max_tokens` to `Config` struct**

  File: `synapse-core/src/config.rs`

  1. Add `default_max_tokens()` function returning `4096u32` near other default functions.
  2. Add `max_tokens: u32` field to `Config` struct (between `model` and `system_prompt`) with `#[serde(default = "default_max_tokens")]`.
  3. Add `max_tokens: default_max_tokens()` to `Config::default()` implementation.
  4. Add unit test `test_config_default_max_tokens` that:
     - Parses an empty TOML string and asserts `config.max_tokens == 4096`.
     - Parses a TOML string with `max_tokens = 8192` and asserts `config.max_tokens == 8192`.

  **Acceptance criteria:**
  - `Config` has a public `max_tokens: u32` field deserializable from TOML; omitting it from config yields `4096`.
  - `test_config_default_max_tokens` exists and passes with both the default and explicit value cases.

- [x] **Task 2a: Update `AnthropicProvider` constructor and usages**

  File: `synapse-core/src/provider/anthropic.rs`

  1. Add `max_tokens: u32` field to `AnthropicProvider` struct.
  2. Update `new()` to accept `max_tokens: u32` as the third parameter and store it.
  3. Replace `DEFAULT_MAX_TOKENS` with `self.max_tokens` in `complete()` and `complete_with_tools()`.
  4. Remove `const DEFAULT_MAX_TOKENS: u32 = 1024;`.
  5. Update `test_anthropic_provider_new` to pass `4096` as the third argument and assert the field.
  6. Update doc comment example for `AnthropicProvider::new` to show three parameters.

  **Acceptance criteria:**
  - `AnthropicProvider::new` accepts a third `max_tokens: u32` parameter and the struct stores it.
  - All provider trait methods that build API request bodies use `self.max_tokens`; no `DEFAULT_MAX_TOKENS` constant remains in this file.

- [x] **Task 2b: Update `DeepSeekProvider` constructor and usages**

  File: `synapse-core/src/provider/deepseek.rs`

  1. Add `max_tokens: u32` field to `DeepSeekProvider` struct.
  2. Update `new()` to accept `max_tokens: u32` as the third parameter and store it.
  3. Replace `DEFAULT_MAX_TOKENS` with `self.max_tokens` in `complete()`, `complete_with_tools()`, and `stream()`.
  4. Remove `DEFAULT_MAX_TOKENS` from the import (change `use super::openai_compat::{self, DEFAULT_MAX_TOKENS};` to `use super::openai_compat;`).
  5. Update `test_deepseek_provider_new` to pass `4096` as the third argument and assert the field.
  6. Update doc comment example for `DeepSeekProvider::new` to show three parameters.

  **Acceptance criteria:**
  - `DeepSeekProvider::new` accepts a third `max_tokens: u32` parameter and the struct stores it.
  - All provider trait methods that build API request bodies use `self.max_tokens`; no `DEFAULT_MAX_TOKENS` import or reference remains in this file.

- [x] **Task 2c: Update `OpenAiProvider` constructor and usages**

  File: `synapse-core/src/provider/openai.rs`

  1. Add `max_tokens: u32` field to `OpenAiProvider` struct.
  2. Update `new()` to accept `max_tokens: u32` as the third parameter and store it.
  3. Replace `DEFAULT_MAX_TOKENS` with `self.max_tokens` in `complete()`, `complete_with_tools()`, and `stream()`.
  4. Remove `DEFAULT_MAX_TOKENS` from the import (change `use super::openai_compat::{self, DEFAULT_MAX_TOKENS};` to `use super::openai_compat;`).
  5. Update `test_openai_provider_new` to pass `4096` as the third argument and assert the field.

  **Acceptance criteria:**
  - `OpenAiProvider::new` accepts a third `max_tokens: u32` parameter and the struct stores it.
  - All provider trait methods that build API request bodies use `self.max_tokens`; no `DEFAULT_MAX_TOKENS` import or reference remains in this file.

- [x] **Task 3: Remove `DEFAULT_MAX_TOKENS` from `openai_compat.rs`**

  File: `synapse-core/src/provider/openai_compat.rs`

  1. Remove `pub(super) const DEFAULT_MAX_TOKENS: u32 = 1024;`.
  2. Remove or delete the `test_default_max_tokens` test that asserts the constant value (constant is deleted, test is no longer meaningful).
  3. Leave `stream_sse()` signature unchanged (it already accepts `max_tokens: u32` as a parameter and does not reference the constant internally).
  4. Leave wire-format serialization tests that use the literal `1024` in `ApiRequest` construction unchanged (they do not reference the deleted constant).

  **Acceptance criteria:**
  - `DEFAULT_MAX_TOKENS` constant is absent from `openai_compat.rs`.
  - `cargo clippy -- -D warnings` reports no dead-code warnings related to `DEFAULT_MAX_TOKENS`.

- [x] **Task 4: Update provider factory to pass `max_tokens`**

  File: `synapse-core/src/provider/factory.rs`

  1. Pass `config.max_tokens` as the third argument to each provider constructor in the match arms:
     - `DeepSeekProvider::new(api_key, &config.model, config.max_tokens)`
     - `AnthropicProvider::new(api_key, &config.model, config.max_tokens)`
     - `OpenAiProvider::new(api_key, &config.model, config.max_tokens)`
  2. Update the `make_config()` test helper to include `max_tokens: 4096` in the `Config` struct literal.

  **Acceptance criteria:**
  - `create_provider()` passes `config.max_tokens` to all three provider constructors.
  - All factory tests compile and pass with the updated `make_config()` helper.

- [x] **Task 5: Update `config.example.toml`**

  File: `config.example.toml`

  1. Add after the `model` line:
     ```toml
     # Maximum tokens for LLM responses (default: 4096)
     # Higher values allow longer responses but may increase API costs.
     # max_tokens = 4096
     ```

  **Acceptance criteria:**
  - `config.example.toml` contains a commented-out `max_tokens` entry with an explanatory comment.

- [x] **Task 6: Run pre-commit checks**

  1. Run `cargo fmt --check` — must pass with no formatting issues.
  2. Run `cargo clippy -- -D warnings` — must pass with zero warnings.
  3. Run `cargo test` — all tests must be green, including the new `test_config_default_max_tokens`.

  **Acceptance criteria:**
  - All three pre-commit commands exit with code 0.
  - `test_config_default_max_tokens` is present in the test output and passes.
