# SY-14 Research: Phase 13 -- System Prompt

## Overview

Wire `config.system_prompt` through the `Agent` so it prepends a `Role::System` message before every provider call without mutating the stored session history.

---

## Existing Infrastructure

### 1. `Role::System` (READY)

**File:** `/Users/comrade77/RustroverProjects/synapse/synapse-core/src/message.rs`

`Role::System` already exists in the enum at line 13. It serializes to `"system"` and is fully functional. `Message::new(Role::System, "...")` works out of the box.

### 2. `Session.system_prompt` (READY)

**File:** `/Users/comrade77/RustroverProjects/synapse/synapse-core/src/session.rs`

The `Session` struct already has:
- `pub system_prompt: Option<String>` (line 26)
- `pub fn with_system_prompt(self, prompt: impl Into<String>) -> Self` builder (line 57)
- Default is `None` (line 44)
- Tests exist verifying the field and builder (lines 164-183)

### 3. Database Column `system_prompt TEXT` (READY)

**File:** `/Users/comrade77/RustroverProjects/synapse/synapse-core/migrations/20250125_001_initial.sql`

The `sessions` table already has `system_prompt TEXT` at line 7. The `SqliteStore` already reads and writes this column:
- `create_session()` binds `session.system_prompt` (sqlite.rs line 129)
- `get_session()` reads `system_prompt` from the row (sqlite.rs line 173)

No new migration is needed.

### 4. Provider System Message Handling (READY)

All three providers already handle `Role::System` messages:

- **Anthropic** (`anthropic.rs`): Has `extract_system()` (line 141) which extracts system messages from the `messages` array and passes them as the `system` parameter in the API request. The `build_api_messages()` method filters out system messages from the messages array (line 72). This is the correct Anthropic API behavior.

- **DeepSeek** (`deepseek.rs`): Maps `Role::System` to `"system"` role in the messages array (line 73). OpenAI-compatible APIs support system messages inline.

- **OpenAI** (`openai.rs`): Maps `Role::System` to `"system"` role in the messages array (line 50). Standard OpenAI behavior.

- **Mock** (`mock.rs`): Ignores messages entirely, just returns configured responses.

**Conclusion:** No provider changes are needed. Prepending a `Message::new(Role::System, ...)` to the messages array will work correctly for all providers.

---

## Components That Need Changes

### Task 13.1: Add `system_prompt: Option<String>` to `Config`

**File:** `/Users/comrade77/RustroverProjects/synapse/synapse-core/src/config.rs`

The `Config` struct (line 34) currently has 6 fields: `provider`, `api_key`, `model`, `session`, `mcp`, `telegram`. It does NOT have `system_prompt`.

**Required change:**
- Add `#[serde(default)] pub system_prompt: Option<String>` to the `Config` struct
- Update `Config::default()` (line 196) to include `system_prompt: None`
- Add unit test: parse TOML with `system_prompt = "..."`, verify it deserializes
- Add unit test: parse TOML without `system_prompt`, verify it defaults to `None`

**Pattern to follow:** The `api_key` field uses the same `Option<String>` pattern with `#[serde(default)]`.

### Task 13.2: Add `system_prompt` field and `with_system_prompt()` builder to `Agent`

**File:** `/Users/comrade77/RustroverProjects/synapse/synapse-core/src/agent.rs`

The `Agent` struct (line 57) currently has 2 fields: `provider`, `mcp_client`.

**Required changes:**
- Add `system_prompt: Option<String>` field to `Agent`
- Initialize to `None` in `Agent::new()` (line 71) -- maintains backward compatibility
- Add `pub fn with_system_prompt(mut self, prompt: impl Into<String>) -> Self` builder method
- Update doc comment and example to show `with_system_prompt` usage

**Existing pattern:** The `Session::with_system_prompt()` builder at session.rs line 57 is the exact pattern to follow.

### Task 13.3: Implement `build_messages()` helper

**File:** `/Users/comrade77/RustroverProjects/synapse/synapse-core/src/agent.rs`

**Required changes:**
- Add private method `fn build_messages(&self, messages: &[Message]) -> Vec<Message>`
- If `self.system_prompt` is `Some(prompt)`, prepend `Message::new(Role::System, prompt)` to a new vec, then extend with all provided messages
- If `self.system_prompt` is `None`, return `messages.to_vec()`
- Integrate into `complete()` (line 88): call `build_messages()` on the messages slice before passing to the provider
- Integrate into `stream()` (line 138): call `build_messages()` before passing to `provider.stream()`
- Integrate into `stream_owned()` (line 176): call `build_messages()` before passing to `provider.stream()`

**Critical design point:** `build_messages()` creates a new `Vec<Message>` each time. The original `messages` parameter (which is `&mut Vec<Message>` in `complete()`) must NOT have the system message appended to it. The system message only exists in the temporary vec passed to the provider.

**Integration points in `complete()` (line 88-129):**
- Line 92-96: The provider call `self.provider.complete(messages)` and `self.provider.complete_with_tools(messages, &tools)` -- these need to use `build_messages()` output instead of raw `messages`
- However, `messages` is also mutated in-place to add tool call results (lines 103-119). The system prompt should be prepended to the provider call each iteration, but tool results are appended to the original `messages` vec.

**Detailed `complete()` integration strategy:**
```
for _ in 0..MAX_ITERATIONS {
    let provider_messages = self.build_messages(messages);
    let response = if tools.is_empty() {
        self.provider.complete(&provider_messages).await?
    } else {
        self.provider.complete_with_tools(&provider_messages, &tools).await?
    };
    // ... tool call handling appends to `messages` (not provider_messages)
}
```

This ensures:
1. System prompt is prepended on every provider call
2. Tool call results are appended to the original messages (which get stored in DB by callers)
3. System prompt is never stored in DB (it only exists in the temporary `provider_messages`)

**Integration points in `stream()` (line 138-169):**
- Line 147: `self.provider.stream(messages)` -- needs `build_messages()` output
- The `stream()` without tools just delegates to `provider.stream()`, so it needs to build messages once and pass the result

**Integration points in `stream_owned()` (line 176-207):**
- Line 185: `self.provider.stream(&messages)` -- needs `build_messages()` output
- Line 195: `self.complete(&mut messages)` -- `complete()` already calls `build_messages()` internally, so this is handled

### Task 13.4: Wire system prompt in CLI and Telegram

#### CLI One-Shot Mode

**File:** `/Users/comrade77/RustroverProjects/synapse/synapse-cli/src/main.rs`

Line 184: `let agent = Agent::new(provider, mcp_client);`

**Required change:**
```rust
let mut agent = Agent::new(provider, mcp_client);
if let Some(ref prompt) = config.system_prompt {
    agent = agent.with_system_prompt(prompt);
}
```

Or more idiomatically with the builder pattern:
```rust
let agent = {
    let a = Agent::new(provider, mcp_client);
    match config.system_prompt {
        Some(ref prompt) => a.with_system_prompt(prompt),
        None => a,
    }
};
```

#### CLI REPL Mode

**File:** `/Users/comrade77/RustroverProjects/synapse/synapse-cli/src/repl.rs`

Line 498: `let agent = Agent::new(provider, mcp_client);`

**Required change:** Same pattern as one-shot mode. The REPL's `run_repl()` function takes `config: &Config`, so `config.system_prompt` is accessible.

Note: The `run_repl()` function signature (line 464) already receives `config: &Config`, so no signature change is needed.

#### Telegram Bot Main

**File:** `/Users/comrade77/RustroverProjects/synapse/synapse-telegram/src/main.rs`

Line 83: `let agent = Arc::new(Agent::new(provider, mcp_client));`

**Required change:**
```rust
let agent = {
    let a = Agent::new(provider, mcp_client);
    match config.system_prompt {
        Some(ref prompt) => a.with_system_prompt(prompt),
        None => a,
    }
};
let agent = Arc::new(agent);
```

Note: `config` is still a plain `Config` at this point (it gets wrapped in `Arc` at line 94), so `config.system_prompt` is accessible.

### Task 13.5: Update `config.example.toml`

**File:** `/Users/comrade77/RustroverProjects/synapse/config.example.toml`

**Required change:** Add a commented `system_prompt` example after the `model` field and before the `[session]` section (between lines 21 and 23):

```toml
# System prompt to prepend to every LLM conversation
# This shapes the AI's personality and instructions across all interactions.
# Keep it concise to minimize token usage.
# system_prompt = "You are a helpful programming assistant."
```

---

## Dependencies and Patterns

### `lib.rs` Re-exports

**File:** `/Users/comrade77/RustroverProjects/synapse/synapse-core/src/lib.rs`

Line 15 re-exports: `pub use config::{Config, ConfigError, McpSettings, SessionConfig, TelegramConfig};`

No change needed -- `Config` is already re-exported, and `system_prompt` is just a new field on it.

### Agent Export

Line 14: `pub use agent::{Agent, AgentError};`

No change needed -- `Agent` is already exported.

---

## Provider-Specific Considerations

### Anthropic System Prompt Handling

The `AnthropicProvider::extract_system()` method (anthropic.rs line 141-155) extracts `Role::System` messages from the messages array and joins them with `"\n\n"`. It then passes the extracted text as the top-level `system` field in the API request (anthropic.rs line 335, 354).

The `build_api_messages()` method (anthropic.rs line 69) filters OUT system messages (line 72: `filter(|m| m.role != Role::System)`).

**Implication:** When `Agent::build_messages()` prepends a `Role::System` message, the Anthropic provider will:
1. Extract it via `extract_system()` and place it in the `system` API parameter
2. Filter it out of the `messages` array via `build_api_messages()`

This is exactly correct. No provider changes needed.

### DeepSeek and OpenAI System Prompt Handling

Both pass `Role::System` messages inline in the messages array as `"system"` role. This is the standard OpenAI-compatible behavior. No special handling needed.

---

## Test Strategy

### Unit Tests for `Config`

1. `test_config_with_system_prompt` -- Parse TOML with `system_prompt = "You are helpful."`, verify `config.system_prompt == Some("You are helpful.")`
2. `test_config_without_system_prompt` -- Parse TOML without the field, verify `config.system_prompt == None`
3. `test_config_default_system_prompt` -- Verify `Config::default().system_prompt == None`

### Unit Tests for `Agent`

1. `test_agent_with_system_prompt` -- Create agent with `with_system_prompt()`, verify field is set
2. `test_agent_without_system_prompt` -- Create agent with `Agent::new()`, verify `system_prompt` is `None`
3. `test_build_messages_with_system_prompt` -- Verify prepended `Role::System` message when `system_prompt` is `Some`
4. `test_build_messages_without_system_prompt` -- Verify messages returned unchanged when `system_prompt` is `None`
5. `test_build_messages_does_not_mutate_original` -- Verify the original messages vec is not mutated (system message only in the returned vec)
6. `test_agent_complete_with_system_prompt` -- Use MockProvider, verify system prompt is prepended (can be tested by checking the messages passed to provider)

### Note on MockProvider Limitation

The current `MockProvider` ignores the `messages` parameter entirely (mock.rs line 177: `_messages: &[Message]`). To verify that `build_messages()` prepends the system prompt, we have two options:
1. Add a `received_messages` capture to MockProvider (more complex, but thorough)
2. Test `build_messages()` directly as a private method test within the `agent.rs` `#[cfg(test)]` module (simpler, recommended)

The PRD specifies `build_messages()` as a private helper, so testing it directly within the module's test section is appropriate.

---

## Deviations from Requirements

**None.** The existing codebase is well-aligned with the requirements:
- `Role::System` exists and works
- `Session.system_prompt` exists with builder
- DB column exists
- All providers handle `Role::System` correctly
- `Agent::new()` will remain backward-compatible with the builder pattern addition
- No schema changes needed

---

## Risks

| Risk | Likelihood | Impact | Mitigation |
|------|-----------|--------|------------|
| System prompt duplicated in DB | Low | Medium | `build_messages()` creates a temporary vec; original messages are never mutated with the system message. Unit tests verify this. |
| Breaking change to `Agent::new()` | None | High | `Agent::new()` signature is unchanged. `system_prompt` defaults to `None`. `with_system_prompt()` is an optional builder. |
| Anthropic double system prompt | Low | Low | Anthropic provider already extracts system messages and places them in the `system` API field. A single prepended system message will be correctly handled. |
| Long system prompts increasing cost | Low | Low | Documentation in `config.example.toml` advises keeping prompts concise. User responsibility. |

---

## Implementation Order

1. **Task 13.1** -- `Config.system_prompt` field + tests (no dependencies)
2. **Task 13.2** -- `Agent.system_prompt` field + `with_system_prompt()` builder + tests (no external dependencies)
3. **Task 13.3** -- `Agent::build_messages()` helper + integration into `complete()`/`stream()`/`stream_owned()` + tests (depends on 13.2)
4. **Task 13.4** -- Wire in CLI main, REPL, and Telegram (depends on 13.1 + 13.3)
5. **Task 13.5** -- Update `config.example.toml` (independent, can be done anytime)

Tasks 13.1 and 13.2 can be done in parallel. Task 13.3 depends on 13.2. Task 13.4 depends on both 13.1 and 13.3.

---

## Resolved Questions

All requirements are clear. No open questions remain. The existing plumbing (`Role::System`, `Session.system_prompt`, DB column, provider system message handling) is fully in place and verified through code inspection.
